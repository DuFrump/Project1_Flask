import joblib
from konlpy.tag import Okt
from flask import Flask, request, jsonify
import numpy as np # numpyë¥¼ ì„í¬íŠ¸í•˜ë©´ ë” ì•ˆì •ì ì…ë‹ˆë‹¤.
from flask_cors import CORS
from topic_utils import tokenize

# --- Flask ì•± ìƒì„± ---
app = Flask(__name__)
CORS(app, origins=["https://interest-56pc.onrender.com"])

@app.route('api-topic', methods=['POST'])
def analyze_topic():
    data = request.get_json()
    sentence = data.get('sentence', '')
    # ì˜ˆì‹œ: ë”ë¯¸ ë°ì´í„° ë°˜í™˜
    return jsonify({
        "scores": {
            "ì˜í™”/ë¯¸ë””ì–´": 30,
            "ìŠ¤í¬ì¸ ": 20.0,
            "ê²½ì œ/ì¬í…Œí¬": 10.0,
            "ê¸°ìˆ /IT": 25.0,
            "ì¼ìƒ/ì—¬í–‰": 14.5,
            "ê¸°íƒ€_ì£¼ì œ" : 0.5
        }
    })

# --- 2. í•™ìŠµ ë•Œì™€ ë™ì¼í•œ í† í¬ë‚˜ì´ì € í•¨ìˆ˜ ì •ì˜ ---
# okt = Okt()
# def tokenize(text):
#     return [word for word, pos in okt.pos(text, stem=True) if pos in ['Noun', 'Verb', 'Adjective']]

# --- 1. ëª¨ë¸ê³¼ í•„ìš” ë„êµ¬ë¥¼ ë¯¸ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° ---
print("ğŸš€ ëª¨ë¸ê³¼ ë„êµ¬ë“¤ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
try:
    model = joblib.load('./korean_topic_model.pkl')
    vectorizer = joblib.load('./tfidf_vectorizer.pkl')
    label_encoder = joblib.load('./label_encoder.pkl')
    print("âœ… ëª¨ë¸ê³¼ ë„êµ¬ ë¡œë”© ì™„ë£Œ.")
except FileNotFoundError:
    print("âŒ ì˜¤ë¥˜: ì €ì¥ëœ ëª¨ë¸ íŒŒì¼(.pkl)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# --- 3. ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  API ì—”ë“œí¬ì¸íŠ¸ ì •ì˜ ---
@app.route('/predict', methods=['POST'])
def predict():
    data = request.get_json()
    user_input = data.get('sentence')
    
    if not user_input or not user_input.strip():
        return jsonify({'error': 'sentence í‚¤ê°€ ì—†ê±°ë‚˜ ë¬¸ì¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.'}), 400

    sentences = [s.strip() for s in user_input.replace(',', '.').split('.') if s.strip()]
    processed_input = user_input
    if len(sentences) > 1:
        last_sentence = sentences[-1]
        processed_input = user_input + " " + (last_sentence + " ") * 2
    
    # --- ì˜ˆì¸¡ ìˆ˜í–‰ ---
    input_vec = vectorizer.transform([processed_input])
    probabilities = model.predict_proba(input_vec)[0]

    # âœ¨ ìˆ˜ì •ëœ ë¶€ë¶„: NumPy floatë¥¼ Python floatìœ¼ë¡œ ë³€í™˜
    scores_dict = {
        topic: round(float(prob) * 100, 2) 
        for topic, prob in zip(label_encoder.classes_, probabilities)
    }

    return jsonify({'scores': scores_dict})

# --- 4. API ì„œë²„ ì‹¤í–‰ ---
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)